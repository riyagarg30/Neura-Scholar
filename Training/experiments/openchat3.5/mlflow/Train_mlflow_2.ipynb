{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf92002-b247-4de0-813a-cfeec84ef256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers>=2.2.2 in /opt/conda/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.5.1+cpu)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.20.1+cpu)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: mlflow in /opt/conda/lib/python3.12/site-packages (2.22.0)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.12/site-packages (2.0.37)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: ray[train] in /opt/conda/lib/python3.12/site-packages (2.46.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers>=2.2.2) (4.51.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence-transformers>=2.2.2) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers>=2.2.2) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers>=2.2.2) (0.31.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers>=2.2.2) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers>=2.2.2) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.12/site-packages (from ray[train]) (8.1.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from ray[train]) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.12/site-packages (from ray[train]) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from ray[train]) (1.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from ray[train]) (24.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.12/site-packages (from ray[train]) (5.28.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from ray[train]) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from ray[train]) (2.32.3)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.12/site-packages (from ray[train]) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=9.0.0 in /opt/conda/lib/python3.12/site-packages (from ray[train]) (19.0.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from ray[train]) (2024.12.0)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /opt/conda/lib/python3.12/site-packages (from ray[train]) (2.10.6)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: mlflow-skinny==2.22.0 in /opt/conda/lib/python3.12/site-packages (from mlflow) (2.22.0)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.12/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.12/site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.12/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.12/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/conda/lib/python3.12/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.12/site-packages (from mlflow) (3.8)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.12/site-packages (from mlflow) (3.10.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.52.0)\n",
      "Requirement already satisfied: fastapi<1 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (1.33.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (1.33.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n",
      "Requirement already satisfied: uvicorn<1 in /opt/conda/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.8)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/conda/lib/python3.12/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.2.2) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[train]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[train]) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->ray[train]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->ray[train]) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->ray[train]) (2024.12.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.2.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.2.2) (3.5.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2) (0.21.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema->ray[train]) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema->ray[train]) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema->ray[train]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema->ray[train]) (0.22.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.40.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/conda/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.54b0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.14.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.12/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.8.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sentence-transformers>=2.2.2\" ray[train] torch torchvision accelerate mlflow psycopg2-binary pandas sqlalchemy numpy tqdm datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "560889f1-07f1-453f-bbc3-5382aea61643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 21:51:54 - Use pytorch device_name: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a3bd356bd8471c84b3da63fd3f381e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 13:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:05:45 - Saving model checkpoint to output/arxiv-model-20250509-215154/checkpoint-600\n",
      "2025-05-09 22:05:45 - Save model to output/arxiv-model-20250509-215154/checkpoint-600\n",
      "2025-05-09 22:05:47 - Save model to output/arxiv-model-20250509-215154\n",
      "2025-05-09 22:06:25 - Save model to /tmp/tmpu_mce60e/model/model.sentence_transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/09 22:06:25 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/09 22:06:49 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.20.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torchvision==0.20.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Successfully registered model 'distilbert-arxiv-bi-encoder1'.\n",
      "2025/05/09 22:07:04 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: distilbert-arxiv-bi-encoder1, version 1\n",
      "Created version '1' of model 'distilbert-arxiv-bi-encoder1'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run carefree-wren-174 at: http://129.114.27.112:8000/#/experiments/2/runs/d1494deb427848008521c0611e6eecd4\n",
      "ðŸ§ª View experiment at: http://129.114.27.112:8000/#/experiments/2\n",
      " Training complete. Model saved to: output/arxiv-model-20250509-215154\n",
      "http://129.114.27.112:8000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://129.114.27.112:8000\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://129.114.27.112:9000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"admin\"\n",
    "\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin@123\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"admin\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"password\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#mlflow.set_experiment(\"arxiv-bi-encoder\")\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, LoggingHandler, util\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://192.5.87.131:30003\"\n",
    "#os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://192.5.87.131:30000\"\n",
    "#os.environ[\"AWS_ACCESS_KEY_ID\"] = \"admin\"\n",
    "#os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin@123\"\n",
    "#os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"admin\"\n",
    "#os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"password\"\n",
    "#mlflow.set_tracking_uri(\"http://192.5.87.131:30003\")\n",
    "#mlflow.set_experiment(\"arxiv-bi-encoder\")\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "#mlflow.set_experiment(\"distilbert-arxiv-bi-encoder1\")\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "df = pd.read_csv(\"arxiv_chunks_training_4_phrases1.csv\").head(200)\n",
    "\n",
    "train_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        queries = json.loads(row['query']) if isinstance(row['query'], str) else row['query']\n",
    "        if isinstance(queries, list):\n",
    "            for q in queries:\n",
    "                if isinstance(q, str) and len(q.strip()) > 0:\n",
    "                    train_examples.append(InputExample(texts=[q.strip(), row['chunk_data']]))\n",
    "        elif isinstance(queries, str):\n",
    "            if len(queries.strip()) > 0:\n",
    "                train_examples.append(InputExample(texts=[queries.strip(), row['chunk_data']]))\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row due to error: {e}\")\n",
    "\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "max_seq_length = 512\n",
    "batch_size = 1\n",
    "epochs = 1\n",
    "model_save_path = f'output/arxiv-model-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode_mean_tokens=True)\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"model_name\": model_name,\n",
    "        \"train_batch_size\": batch_size,\n",
    "        \"max_seq_length\": max_seq_length,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"pooling\": \"mean\"\n",
    "    })\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=epochs,\n",
    "        warmup_steps=int(0.1 * len(train_dataloader)),\n",
    "        show_progress_bar=True,\n",
    "        use_amp=True,\n",
    "        optimizer_params={\"lr\": 2e-5},\n",
    "        checkpoint_path=model_save_path,\n",
    "        checkpoint_save_steps=len(train_dataloader)\n",
    "    )\n",
    "\n",
    "    model.save(model_save_path)\n",
    "    mlflow.log_artifacts(model_save_path, artifact_path=\"model\")\n",
    "    mlflow.sentence_transformers.log_model(model, artifact_path=\"model\", registered_model_name=\"distilbert-arxiv-bi-encoder1\")\n",
    "\n",
    "print(f\" Training complete. Model saved to: {model_save_path}\")\n",
    "\n",
    "print(os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "372b6164-ef18-47e5-abdb-c31071bf689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:12:27 - Use pytorch device_name: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02492ca56f9f40d795b334146b607e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 20:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:32:41 - Saving model checkpoint to output/arxiv-model-20250509-221226/checkpoint-570\n",
      "2025-05-09 22:32:41 - Save model to output/arxiv-model-20250509-221226/checkpoint-570\n",
      "2025-05-09 22:32:43 - Save model to output/arxiv-model-20250509-221226\n",
      "2025-05-09 22:33:20 - Save model to /tmp/tmpbzjsk8pa/model/model.sentence_transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/09 22:33:21 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/09 22:33:34 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.20.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torchvision==0.20.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Registered model 'distilbert-arxiv-bi-encoder1' already exists. Creating a new version of this model...\n",
      "2025/05/09 22:33:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: distilbert-arxiv-bi-encoder1, version 2\n",
      "Created version '2' of model 'distilbert-arxiv-bi-encoder1'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run vaunted-shark-785 at: http://129.114.27.112:8000/#/experiments/2/runs/a10422d7f2f14158b94aa2b76d57188b\n",
      "ðŸ§ª View experiment at: http://129.114.27.112:8000/#/experiments/2\n",
      " Training complete. Model saved to: output/arxiv-model-20250509-221226\n",
      "http://129.114.27.112:8000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://129.114.27.112:8000\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://129.114.27.112:9000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"admin\"\n",
    "\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin@123\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"admin\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"password\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#mlflow.set_experiment(\"arxiv-bi-encoder\")\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, LoggingHandler, util\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://192.5.87.131:30003\"\n",
    "#os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://192.5.87.131:30000\"\n",
    "#os.environ[\"AWS_ACCESS_KEY_ID\"] = \"admin\"\n",
    "#os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin@123\"\n",
    "#os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"admin\"\n",
    "#os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"password\"\n",
    "#mlflow.set_tracking_uri(\"http://192.5.87.131:30003\")\n",
    "#mlflow.set_experiment(\"arxiv-bi-encoder\")\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "#mlflow.set_experiment(\"distilbert-arxiv-bi-encoder1\")\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "df = pd.read_csv(\"arxiv_chunks_training_4_phrases1.csv\").head(380)\n",
    "\n",
    "train_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        queries = json.loads(row['query']) if isinstance(row['query'], str) else row['query']\n",
    "        if isinstance(queries, list):\n",
    "            for q in queries:\n",
    "                if isinstance(q, str) and len(q.strip()) > 0:\n",
    "                    train_examples.append(InputExample(texts=[q.strip(), row['chunk_data']]))\n",
    "        elif isinstance(queries, str):\n",
    "            if len(queries.strip()) > 0:\n",
    "                train_examples.append(InputExample(texts=[queries.strip(), row['chunk_data']]))\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row due to error: {e}\")\n",
    "\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "max_seq_length = 512\n",
    "batch_size = 2\n",
    "epochs = 1\n",
    "model_save_path = f'output/arxiv-model-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode_mean_tokens=True)\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"model_name\": model_name,\n",
    "        \"train_batch_size\": batch_size,\n",
    "        \"max_seq_length\": max_seq_length,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"pooling\": \"mean\"\n",
    "    })\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=epochs,\n",
    "        warmup_steps=int(0.1 * len(train_dataloader)),\n",
    "        show_progress_bar=True,\n",
    "        use_amp=True,\n",
    "        optimizer_params={\"lr\": 2e-5},\n",
    "        checkpoint_path=model_save_path,\n",
    "        checkpoint_save_steps=len(train_dataloader)\n",
    "    )\n",
    "\n",
    "    model.save(model_save_path)\n",
    "    mlflow.log_artifacts(model_save_path, artifact_path=\"model\")\n",
    "    mlflow.sentence_transformers.log_model(model, artifact_path=\"model\", registered_model_name=\"distilbert-arxiv-bi-encoder1\")\n",
    "\n",
    "print(f\" Training complete. Model saved to: {model_save_path}\")\n",
    "\n",
    "print(os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3b5f6-5a04-4fcf-ab80-75520bf35075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
